{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# DLinear + TimesNet + TimeMixer Training & Backtesting\n\nThis notebook demonstrates how to:\n1. Load per-asset OHLCV candle data from the `tensorlink-dev/open-synth-training-data` HF dataset\n2. Engineer 16 micro-structure features per 1-hour bar using `OHLCVEngineer`\n3. Build a hybrid model using **DLinearBlock**, **TimesNetBlock**, and **TimeMixerBlock**\n4. Choose between **HorizonHead** (per-step mu/sigma via cross-attention) or **NeuralBridgeHead** (macro return + micro texture with bridge constraints)\n5. Train with CRPS loss and backtest with multi-interval scoring"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "source": "import sys\nimport os\n\n# Ensure the project root is on the path\nPROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\nif PROJECT_ROOT not in sys.path:\n    sys.path.insert(0, PROJECT_ROOT)\nos.chdir(PROJECT_ROOT)\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom src.models.registry import discover_components, registry\nfrom src.models.factory import HybridBackbone, SynthModel\nfrom src.models.heads import HorizonHead, NeuralBridgeHead, GBMHead, SDEHead\nfrom src.data.market_data_loader import (\n    HFOHLCVSource,\n    MockDataSource,\n    OHLCVEngineer,\n    OHLCV_FEATURE_NAMES,\n    MarketDataLoader,\n    ZScoreEngineer,\n)\nfrom src.research.trainer import Trainer, DataToModelAdapter\nfrom src.research.metrics import (\n    crps_ensemble,\n    CRPSMultiIntervalScorer,\n    SCORING_INTERVALS,\n)\n\n# Auto-discover all registered blocks\ndiscover_components(\"src/models/components\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nprint(f\"Registered blocks: {list(registry.blocks.keys())}\")\nprint(f\"OHLCV feature count: {len(OHLCV_FEATURE_NAMES)}\")\nprint(f\"Features: {OHLCV_FEATURE_NAMES}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Commented out IPython magic to ensure Python compatibility.\n# 2. Clone the repository\n!git clone https://github.com/tensorlink-dev/open-synth-miner\n# %cd open-synth-miner\n!uv pip install torchsde\n# 3. Install dependencies using uv\n# --system: Installs into the Colab runtime (no venv needed)\n# -e .: Installs the package in editable mode\n!uv pip install --system -e .\n\n# 4. (Optional) Verify installation\n!python main.py --help",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\n\n# Ensure the project root is on the path\nPROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\nif PROJECT_ROOT not in sys.path:\n    sys.path.insert(0, PROJECT_ROOT)\nos.chdir(PROJECT_ROOT)\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom src.models.registry import discover_components, registry\nfrom src.models.factory import HybridBackbone, SynthModel\nfrom src.models.heads import HorizonHead, NeuralBridgeHead\nfrom src.data.market_data_loader import (\n    HFOHLCVSource,\n    MockDataSource,\n    OHLCVEngineer,\n    OHLCV_FEATURE_NAMES,\n    MarketDataLoader,\n)\nfrom src.research.trainer import Trainer, DataToModelAdapter\nfrom src.research.metrics import (\n    crps_ensemble,\n    CRPSMultiIntervalScorer,\n    SCORING_INTERVALS,\n)\n\n# Auto-discover all registered blocks\ndiscover_components(\"src/models/components\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nprint(f\"Registered blocks: {list(registry.blocks.keys())}\")\nprint(f\"OHLCV feature count: {len(OHLCV_FEATURE_NAMES)}\")\nprint(f\"Features: {OHLCV_FEATURE_NAMES}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ----- Data config -----\nREPO_ID = \"tensorlink-dev/open-synth-training-data\"\nTIMEFRAME = \"5m\"  # \"5m\" or \"1m\"\nASSET_FILES = {\n    \"BTC_USD\": \"data/BTC_USD/{timeframe}.parquet\",\n    \"ETH_USD\": \"data/ETH_USD/{timeframe}.parquet\",\n    \"SOL_USD\": \"data/SOL_USD/{timeframe}.parquet\",\n}\nASSETS = list(ASSET_FILES.keys())\nUSE_HF = True"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Data Loading\n\n`HFOHLCVSource` downloads per-asset parquet files from the HF dataset and returns `AssetData`\nwith full OHLCV columns. `OHLCVEngineer` then resamples the raw candles (1m/5m) to 1-hour bars\nand computes 16 micro-structure features:\n\n| Feature | Description |\n|---------|-------------|\n| `open, high, low, close, volume` | Standard 1h OHLCV |\n| `realized_vol` | Intra-hour log-return std |\n| `skew, kurtosis` | Higher moments of intra-hour returns |\n| `parkinson_vol` | Range-based volatility estimator |\n| `efficiency` | Fractal efficiency (net move / total path) |\n| `vwap_dev` | Close deviation from VWAP |\n| `signed_vol_sum` | Net buying pressure |\n| `up_wick, down_wick` | Upper/lower wick ratios |\n| `body_size` | Candle body as fraction of range |\n| `clv` | Close Location Value (-1 to +1) |\n\nSet `USE_HF = False` in the config cell to fall back to `MockDataSource` for offline testing."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "engineer = OHLCVEngineer(resample_rule=\"1h\")\n\nif USE_HF:\n    source = HFOHLCVSource(\n        repo_id=REPO_ID,\n        asset_files=ASSET_FILES,\n        repo_type=\"dataset\",\n        timeframe=TIMEFRAME,\n    )\nelse:\n    # Offline fallback: MockDataSource generates synthetic random-walk prices.\n    # OHLCVEngineer gracefully handles the single-price case (O=H=L=C=price).\n    source = MockDataSource(length=8000, freq=\"5min\", seed=42, base_price=100.0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Validation / Test Split\n",
    "\n",
    "Using a static holdout with a fractional cutoff to create leak-safe temporal splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Retrieve block classes from the registry\nDLinearBlock = registry.get_block(\"dlinearblock\")\nTimesNetBlock = registry.get_block(\"timesnetblock\")\nTimeMixerBlock = registry.get_block(\"timemixerblock\")\n\n# Instantiate the blocks\nblocks = [\n    DLinearBlock(d_model=D_MODEL, kernel_size=DLINEAR_KERNEL),\n    TimesNetBlock(d_model=D_MODEL, top_k=TIMESNET_TOP_K, dropout=0.1),\n    TimeMixerBlock(\n        d_model=D_MODEL,\n        down_sampling_window=TIMEMIXER_DOWN_WINDOW,\n        down_sampling_layers=TIMEMIXER_DOWN_LAYERS,\n        moving_avg_kernel=DLINEAR_KERNEL,\n        dropout=0.1,\n    ),\n    DLinearBlock(d_model=D_MODEL, kernel_size=DLINEAR_KERNEL),\n]\n\nbackbone = HybridBackbone(\n    input_size=FEATURE_DIM,\n    d_model=D_MODEL,\n    blocks=blocks,\n    validate_shapes=True,\n)\n\n# Build the head based on HEAD_TYPE\nif HEAD_TYPE == \"neural_bridge\":\n    head = NeuralBridgeHead(\n        latent_size=backbone.output_dim,\n        micro_steps=MICRO_STEPS,\n        hidden_dim=BRIDGE_HIDDEN,\n    )\n    head_label = f\"NeuralBridgeHead (micro_steps={MICRO_STEPS})\"\nelse:\n    head = HorizonHead(\n        latent_size=backbone.output_dim,\n        horizon_max=HORIZON_MAX,\n        nhead=HORIZON_NHEAD,\n        n_layers=HORIZON_LAYERS,\n        dropout=0.1,\n        kv_dim=128,\n    )\n    head_label = f\"HorizonHead (horizon_max={HORIZON_MAX})\"\n\nmodel = SynthModel(backbone=backbone, head=head).to(device)\n\ntotal_params = sum(p.numel() for p in model.parameters())\nbackbone_params = sum(p.numel() for p in backbone.parameters())\nhead_params = sum(p.numel() for p in head.parameters())\nprint(f\"SynthModel with {head_label} built successfully\")\nprint(f\"  Backbone output dim: {backbone.output_dim}\")\nprint(f\"  Backbone params:     {backbone_params:,}\")\nprint(f\"  Head params:         {head_params:,}\")\nprint(f\"  Total parameters:    {total_params:,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Build the Model\n\n### Backbone\nThe backbone stacks four blocks with complementary inductive biases:\n\n1. **DLinearBlock** — trend-seasonal decomposition with separate linear projections\n2. **TimesNetBlock** — FFT period discovery + 2D Inception convolutions\n3. **TimeMixerBlock** — multi-scale past-decomposable mixing (bottom-up seasonal, top-down trend)\n4. **DLinearBlock** — final decomposition refinement\n\n### Head Options\n\nSet `HEAD_TYPE` in the config cell to switch between:\n\n#### `\"horizon\"` — HorizonHead (per-step mu/sigma via cross-attention)\nGenerates per-step drift and volatility trajectories via learned queries that\ncross-attend to the full backbone sequence. Outputs `(mu_1…mu_H, sigma_1…sigma_H)`\nfor time-varying GBM path simulation.\n\n#### `\"neural_bridge\"` — NeuralBridgeHead (macro return + micro texture)\nHierarchical head that predicts:\n- **Macro destination** — the 1H log-return (where does the price end up?)\n- **Micro texture** — sub-hour path shape (how does it get there?)\n\nUses a *bridge constraint* to force the generated path to start at 0 and end at the\npredicted return. Unlike HorizonHead, this outputs the path tensor **directly** —\nno external simulation loop needed.\n\n```\nh_t (batch, d_model)  ← last-step backbone embedding\n      │\n ┌────┴────┐\n │         │\n ▼         ▼\nmacro_proj  texture_net\n(→ 1H ret)  (→ micro_steps deviations)\n │         │\n │     Bridge constraint\n │     (zero endpoints)\n │         │\n ▼         ▼\nlinear_path + bridge → micro_returns (batch, micro_steps)\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Retrieve block classes from the registry\nDLinearBlock = registry.get_block(\"dlinearblock\")\nTimesNetBlock = registry.get_block(\"timesnetblock\")\nTimeMixerBlock = registry.get_block(\"timemixerblock\")\n\n# Instantiate the blocks\nblocks = [\n    DLinearBlock(d_model=D_MODEL, kernel_size=DLINEAR_KERNEL),\n    TimesNetBlock(d_model=D_MODEL, top_k=TIMESNET_TOP_K, dropout=0.1),\n    TimeMixerBlock(\n        d_model=D_MODEL,\n        down_sampling_window=TIMEMIXER_DOWN_WINDOW,\n        down_sampling_layers=TIMEMIXER_DOWN_LAYERS,\n        moving_avg_kernel=DLINEAR_KERNEL,\n        dropout=0.1,\n    ),\n    DLinearBlock(d_model=D_MODEL, kernel_size=DLINEAR_KERNEL),\n]\n\nbackbone = HybridBackbone(\n    input_size=FEATURE_DIM,\n    d_model=D_MODEL,\n    blocks=blocks,\n    validate_shapes=True,\n)\n\n# Build the head based on HEAD_TYPE\nif HEAD_TYPE == \"neural_bridge\":\n    head = NeuralBridgeHead(\n        latent_size=backbone.output_dim,\n        micro_steps=MICRO_STEPS,\n        hidden_dim=BRIDGE_HIDDEN,\n    )\n    head_label = f\"NeuralBridgeHead (micro_steps={MICRO_STEPS})\"\nelse:\n    head = HorizonHead(\n        latent_size=backbone.output_dim,\n        horizon_max=HORIZON_MAX,\n        nhead=HORIZON_NHEAD,\n        n_layers=HORIZON_LAYERS,\n        dropout=0.1,\n    )\n    head_label = f\"HorizonHead (horizon_max={HORIZON_MAX})\"\n\nmodel = SynthModel(backbone=backbone, head=head).to(device)\n\ntotal_params = sum(p.numel() for p in model.parameters())\nbackbone_params = sum(p.numel() for p in backbone.parameters())\nhead_params = sum(p.numel() for p in head.parameters())\nprint(f\"SynthModel with {head_label} built successfully\")\nprint(f\"  Backbone output dim: {backbone.output_dim}\")\nprint(f\"  Backbone params:     {backbone_params:,}\")\nprint(f\"  Head params:         {head_params:,}\")\nprint(f\"  Total parameters:    {total_params:,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check: Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick smoke test with a dummy batch\ndummy_x = torch.randn(2, INPUT_LEN, FEATURE_DIM, device=device)\ndummy_price = torch.tensor([100.0, 50.0], device=device)\n\nwith torch.no_grad():\n    paths, param_a, param_b = model(dummy_x, initial_price=dummy_price, horizon=PRED_LEN, n_paths=100)\n\nif HEAD_TYPE == \"neural_bridge\":\n    print(f\"Micro path shape:  {paths.shape}      (batch, micro_steps) — direct path output\")\n    print(f\"Macro return shape: {param_a.shape}    (batch, 1) — predicted 1H log-return\")\n    print(f\"\\nSample macro returns: {param_a.detach().cpu().numpy().round(4)}\")\n    print(f\"Sample micro path:   {param_b[0].detach().cpu().numpy().round(4)}\")\nelse:\n    print(f\"Paths shape:     {paths.shape}      (batch, n_paths, horizon)\")\n    print(f\"Mu_seq shape:    {param_a.shape}    (batch, horizon) — per-step drift\")\n    print(f\"Sigma_seq shape: {param_b.shape}  (batch, horizon) — per-step volatility\")\n    print(f\"\\nSample mu trajectory:    {param_a[0].detach().cpu().numpy().round(4)}\")\n    print(f\"Sample sigma trajectory: {param_b[0].detach().cpu().numpy().round(4)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "Uses the `Trainer` class which handles:\n",
    "- `DataToModelAdapter` to bridge `MarketDataLoader` batch format to `SynthModel` inputs\n",
    "- CRPS loss for probabilistic calibration\n",
    "- Sharpness and log-likelihood tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "adapter = DataToModelAdapter(device=device, target_is_log_return=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    n_paths=N_PATHS,\n",
    "    device=device,\n",
    "    adapter=adapter,\n",
    ")\n",
    "\n",
    "# Metric tracking\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_crps\": [],\n",
    "    \"train_sharpness\": [],\n",
    "    \"val_crps\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- Training ---\n",
    "    epoch_losses = []\n",
    "    epoch_crps = []\n",
    "    epoch_sharp = []\n",
    "\n",
    "    for batch in train_dl:\n",
    "        metrics = trainer.train_step(batch)\n",
    "        epoch_losses.append(metrics[\"loss\"])\n",
    "        epoch_crps.append(metrics[\"crps\"])\n",
    "        epoch_sharp.append(metrics[\"sharpness\"])\n",
    "\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    avg_crps = np.mean(epoch_crps)\n",
    "    avg_sharp = np.mean(epoch_sharp)\n",
    "\n",
    "    history[\"train_loss\"].append(avg_loss)\n",
    "    history[\"train_crps\"].append(avg_crps)\n",
    "    history[\"train_sharpness\"].append(avg_sharp)\n",
    "\n",
    "    # --- Validation ---\n",
    "    val_metrics = trainer.validate(val_dl)\n",
    "    history[\"val_crps\"].append(val_metrics[\"val_crps\"])\n",
    "\n",
    "    if epoch % 3 == 0 or epoch == 1:\n",
    "        print(\n",
    "            f\"Epoch {epoch:3d}/{EPOCHS}  \"\n",
    "            f\"train_loss={avg_loss:.5f}  \"\n",
    "            f\"train_crps={avg_crps:.5f}  \"\n",
    "            f\"val_crps={val_metrics['val_crps']:.5f}  \"\n",
    "            f\"sharpness={avg_sharp:.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(history[\"train_loss\"], label=\"Train Loss (CRPS)\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training Loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history[\"train_crps\"], label=\"Train CRPS\")\n",
    "axes[1].plot(history[\"val_crps\"], label=\"Val CRPS\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"CRPS\")\n",
    "axes[1].set_title(\"CRPS: Train vs Validation\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(history[\"train_sharpness\"], label=\"Sharpness\", color=\"tab:green\")\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].set_ylabel(\"Std(paths)\")\n",
    "axes[2].set_title(\"Forecast Sharpness\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Backtesting on Test Set\n",
    "\n",
    "We evaluate the trained model on the held-out test split using the `CRPSMultiIntervalScorer`\n",
    "which computes CRPS at the standard scoring intervals (5min, 30min, 3hour, 24hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "scorer = CRPSMultiIntervalScorer(time_increment=TIME_INCREMENT)\n",
    "\n",
    "interval_scores = {name: [] for name in SCORING_INTERVALS}\n",
    "overall_scores = []\n",
    "all_test_crps = []\n",
    "\n",
    "for batch in test_dl:\n",
    "    adapted = adapter(batch)\n",
    "    history_t = adapted[\"history\"]\n",
    "    initial_price = adapted[\"initial_price\"]\n",
    "    target_factors = adapted[\"target_factors\"]\n",
    "    horizon = target_factors.shape[-1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        paths, mu, sigma = model(\n",
    "            history_t,\n",
    "            initial_price=initial_price,\n",
    "            horizon=horizon,\n",
    "            n_paths=N_PATHS,\n",
    "        )\n",
    "\n",
    "    # Ensemble CRPS on the target factors\n",
    "    sim_paths = paths.transpose(1, 2)  # (batch, horizon, n_paths)\n",
    "    crps_vals = crps_ensemble(sim_paths, target_factors)\n",
    "    all_test_crps.append(crps_vals.mean().item())\n",
    "\n",
    "    # Multi-interval CRPS per sample\n",
    "    for sample_idx in range(paths.shape[0]):\n",
    "        total_crps, detailed = scorer(paths[sample_idx], paths[sample_idx, 0])  # score against median path\n",
    "        overall_scores.append(total_crps)\n",
    "        for row in detailed:\n",
    "            interval_name = row[\"Interval\"]\n",
    "            if interval_name in interval_scores and row[\"Increment\"] == \"Total\":\n",
    "                interval_scores[interval_name].append(float(row[\"CRPS\"]))\n",
    "\n",
    "avg_test_crps = np.mean(all_test_crps)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"BACKTEST RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Average Test CRPS: {avg_test_crps:.6f}\")\n",
    "print(f\"\\nMulti-Interval CRPS Breakdown:\")\n",
    "for name, scores in interval_scores.items():\n",
    "    if scores:\n",
    "        print(f\"  {name:>12s}: {np.mean(scores):.6f} (n={len(scores)})\")\n",
    "    else:\n",
    "        print(f\"  {name:>12s}: N/A (horizon too short for this interval)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fan Chart Visualization\n",
    "\n",
    "Visualize the probabilistic forecasts as fan charts with P5/P50/P95 percentile bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Grab a few test samples for visualization\nmodel.eval()\ntest_batch = next(iter(test_dl))\nadapted = adapter(test_batch)\n\nwith torch.no_grad():\n    paths, mu, sigma = model(\n        adapted[\"history\"],\n        initial_price=adapted[\"initial_price\"],\n        horizon=adapted[\"target_factors\"].shape[-1],\n        n_paths=N_PATHS,\n    )\n\npaths_np = paths.cpu().numpy()           # (batch, n_paths, horizon)\ntargets_np = adapted[\"target_factors\"].cpu().numpy()  # (batch, horizon)\n\nn_show = min(4, paths_np.shape[0])\nfig, axes = plt.subplots(1, n_show, figsize=(5 * n_show, 4), squeeze=False)\n\nfor i in range(n_show):\n    ax = axes[0, i]\n    sample_paths = paths_np[i]  # (n_paths, horizon)\n    t = np.arange(sample_paths.shape[1])\n\n    p5 = np.percentile(sample_paths, 5, axis=0)\n    p25 = np.percentile(sample_paths, 25, axis=0)\n    p50 = np.percentile(sample_paths, 50, axis=0)\n    p75 = np.percentile(sample_paths, 75, axis=0)\n    p95 = np.percentile(sample_paths, 95, axis=0)\n\n    ax.fill_between(t, p5, p95, alpha=0.15, color=\"tab:blue\", label=\"P5-P95\")\n    ax.fill_between(t, p25, p75, alpha=0.3, color=\"tab:blue\", label=\"P25-P75\")\n    ax.plot(t, p50, color=\"tab:blue\", linewidth=2, label=\"Median\")\n    ax.plot(t, targets_np[i], color=\"tab:red\", linewidth=2, linestyle=\"--\", label=\"Actual\")\n\n    ax.set_title(f\"Sample {i}\")\n    ax.set_xlabel(\"Horizon Step\")\n    ax.set_ylabel(\"Price Factor\")\n    if i == 0:\n        ax.legend(fontsize=8)\n\nplt.suptitle(\"DLinear + TimesNet + TimeMixer Fan Charts (Test Set)\", fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Path Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Terminal price distribution for the first test sample\nfig, axes = plt.subplots(1, 3, figsize=(16, 4))\n\nterminal_prices = paths_np[0, :, -1]\naxes[0].hist(terminal_prices, bins=50, alpha=0.7, color=\"tab:blue\", edgecolor=\"white\")\naxes[0].axvline(targets_np[0, -1], color=\"tab:red\", linewidth=2, linestyle=\"--\", label=\"Actual\")\naxes[0].set_title(\"Terminal Price Distribution\")\naxes[0].set_xlabel(\"Price Factor\")\naxes[0].set_ylabel(\"Count\")\naxes[0].legend()\n\n# Per-step mu and sigma trajectories for a few test samples\nmodel.eval()\ntest_batch_viz = next(iter(test_dl))\nadapted_viz = adapter(test_batch_viz)\nwith torch.no_grad():\n    _, mu_viz, sigma_viz = model(\n        adapted_viz[\"history\"],\n        initial_price=adapted_viz[\"initial_price\"],\n        horizon=adapted_viz[\"target_factors\"].shape[-1],\n        n_paths=10,\n    )\nmu_np = mu_viz.cpu().numpy()\nsigma_np = sigma_viz.cpu().numpy()\nt_steps = np.arange(mu_np.shape[-1]) if mu_np.ndim > 1 else np.array([0])\n\nfor i in range(min(4, mu_np.shape[0])):\n    if mu_np.ndim > 1:\n        axes[1].plot(t_steps, mu_np[i], alpha=0.6, label=f\"Sample {i}\" if i < 3 else None)\n        axes[2].plot(t_steps, sigma_np[i], alpha=0.6, label=f\"Sample {i}\" if i < 3 else None)\n    else:\n        axes[1].axhline(mu_np[i], alpha=0.6)\n        axes[2].axhline(sigma_np[i], alpha=0.6)\n\naxes[1].set_xlabel(\"Horizon Step\")\naxes[1].set_ylabel(\"Drift (mu_t)\")\naxes[1].set_title(\"Learned Per-Step Drift\")\naxes[1].legend(fontsize=8)\n\naxes[2].set_xlabel(\"Horizon Step\")\naxes[2].set_ylabel(\"Volatility (sigma_t)\")\naxes[2].set_title(\"Learned Per-Step Volatility\")\naxes[2].legend(fontsize=8)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Summary\n\nThis notebook demonstrated the full training and backtesting workflow within the open-synth-miner framework:\n\n- **Data**: `HFOHLCVSource` loads per-asset OHLCV parquets from `tensorlink-dev/open-synth-training-data`. `OHLCVEngineer` resamples raw candles to 1-hour bars and computes 16 micro-structure features\n- **Backbone**: `HybridBackbone` with `DLinearBlock` + `TimesNetBlock` + `TimeMixerBlock` + `DLinearBlock`\n- **Head**: Selectable via `HEAD_TYPE` config:\n  - `\"horizon\"` — `HorizonHead` cross-attention decoder generating per-step `(mu_t, sigma_t)` for time-varying GBM simulation\n  - `\"neural_bridge\"` — `NeuralBridgeHead` hierarchical head predicting macro 1H return + micro sub-hour texture with bridge constraints (outputs path directly)\n- **Training**: CRPS-optimized via the `Trainer` class\n- **Backtesting**: Multi-interval CRPS evaluation (5min, 30min, 3hour, 24hour)\n\n### Head comparison\n\n| | GBMHead | HorizonHead | NeuralBridgeHead |\n|---|---|---|---|\n| Input | Last step `h[:,-1]` | Full sequence | Last step `h[:,-1]` |\n| Output | `(mu, sigma)` scalars | Per-step `(mu_t, sigma_t)` | `(macro_ret, micro_path)` |\n| Simulation | External GBM | External time-varying GBM | **None** — path is direct |\n| Expressiveness | Constant dynamics | Time-varying drift/vol | Learned texture + bridge |\n| Resolution | N/A | 1 per horizon step | `micro_steps` per hour |"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}